# ServiceMonitor for API metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: neoforge-api-metrics
  namespace: neoforge-monitoring
  labels:
    app: neoforge-api
    component: api-monitoring
    app.kubernetes.io/name: neoforge-api-metrics
    app.kubernetes.io/instance: neoforge-api-metrics
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/part-of: neoforge
spec:
  selector:
    matchLabels:
      app: api
      component: backend
  namespaceSelector:
    matchNames:
    - neoforge
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
  - port: http
    path: /health
    interval: 15s
    scrapeTimeout: 5s
---
# ServiceMonitor for Frontend metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: neoforge-frontend-metrics
  namespace: neoforge-monitoring
  labels:
    app: neoforge-frontend
    component: frontend-monitoring
    app.kubernetes.io/name: neoforge-frontend-metrics
    app.kubernetes.io/instance: neoforge-frontend-metrics
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/part-of: neoforge
spec:
  selector:
    matchLabels:
      app: frontend
      component: web
  namespaceSelector:
    matchNames:
    - neoforge
  endpoints:
  - port: metrics
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
---
# ServiceMonitor for PostgreSQL metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: neoforge-postgres-metrics
  namespace: neoforge-monitoring
  labels:
    app: neoforge-postgres
    component: database-monitoring
    app.kubernetes.io/name: neoforge-postgres-metrics
    app.kubernetes.io/instance: neoforge-postgres-metrics
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/part-of: neoforge
spec:
  selector:
    matchLabels:
      app: postgres
      component: database
  namespaceSelector:
    matchNames:
    - neoforge
  endpoints:
  - port: metrics
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
---
# ServiceMonitor for Redis metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: neoforge-redis-metrics
  namespace: neoforge-monitoring
  labels:
    app: neoforge-redis
    component: cache-monitoring
    app.kubernetes.io/name: neoforge-redis-metrics
    app.kubernetes.io/instance: neoforge-redis-metrics
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/part-of: neoforge
spec:
  selector:
    matchLabels:
      app: redis
      component: cache
  namespaceSelector:
    matchNames:
    - neoforge
  endpoints:
  - port: metrics
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
---
# Prometheus deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: neoforge-monitoring
  labels:
    app: prometheus
    component: metrics-server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: neoforge-prometheus
    app.kubernetes.io/component: metrics-server
    app.kubernetes.io/part-of: neoforge
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: prometheus
      component: metrics-server
  template:
    metadata:
      labels:
        app: prometheus
        component: metrics-server
    spec:
      serviceAccountName: neoforge-monitoring
      securityContext:
        runAsUser: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        fsGroup: 65534
      containers:
      - name: prometheus
        image: prom/prometheus:v2.47.2
        imagePullPolicy: IfNotPresent
        args:
        - --config.file=/etc/prometheus/prometheus.yml
        - --storage.tsdb.path=/prometheus
        - --storage.tsdb.retention.time=30d
        - --storage.tsdb.retention.size=10GB
        - --web.console.libraries=/etc/prometheus/console_libraries
        - --web.console.templates=/etc/prometheus/consoles
        - --web.enable-lifecycle
        - --web.enable-admin-api
        - --log.level=info
        ports:
        - containerPort: 9090
          name: web
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 15
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 5
          periodSeconds: 5
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        persistentVolumeClaim:
          claimName: prometheus-storage
---
# Prometheus service
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: neoforge-monitoring
  labels:
    app: prometheus
    component: metrics-server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: neoforge-prometheus
    app.kubernetes.io/component: metrics-server
    app.kubernetes.io/part-of: neoforge
spec:
  type: ClusterIP
  ports:
  - port: 9090
    targetPort: 9090
    name: web
  selector:
    app: prometheus
    component: metrics-server
---
# Prometheus storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-storage
  namespace: neoforge-monitoring
  labels:
    app: prometheus
    component: storage
    app.kubernetes.io/name: prometheus-storage
    app.kubernetes.io/instance: neoforge-prometheus-storage
    app.kubernetes.io/component: storage
    app.kubernetes.io/part-of: neoforge
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: neoforge-ssd
---
# Grafana deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: neoforge-monitoring
  labels:
    app: grafana
    component: dashboard
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: neoforge-grafana
    app.kubernetes.io/component: dashboard
    app.kubernetes.io/part-of: neoforge
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: grafana
      component: dashboard
  template:
    metadata:
      labels:
        app: grafana
        component: dashboard
    spec:
      securityContext:
        runAsUser: 472
        runAsGroup: 472
        runAsNonRoot: true
        fsGroup: 472
      containers:
      - name: grafana
        image: grafana/grafana:10.1.5
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 3000
          name: grafana
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secret
              key: admin-password
        - name: GF_DATABASE_TYPE
          value: sqlite3
        - name: GF_ANALYTICS_REPORTING_ENABLED
          value: "false"
        - name: GF_ANALYTICS_CHECK_FOR_UPDATES
          value: "false"
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel,grafana-worldmap-panel"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana
        - name: grafana-dashboards
          mountPath: /var/lib/grafana/dashboards
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: false
          runAsNonRoot: true
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-storage
      - name: grafana-config
        configMap:
          name: grafana-config
      - name: grafana-dashboards
        configMap:
          name: grafana-dashboards
---
# Grafana service
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: neoforge-monitoring
  labels:
    app: grafana
    component: dashboard
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: neoforge-grafana
    app.kubernetes.io/component: dashboard
    app.kubernetes.io/part-of: neoforge
spec:
  type: ClusterIP
  ports:
  - port: 3000
    targetPort: 3000
    name: grafana
  selector:
    app: grafana
    component: dashboard
---
# Grafana storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-storage
  namespace: neoforge-monitoring
  labels:
    app: grafana
    component: storage
    app.kubernetes.io/name: grafana-storage
    app.kubernetes.io/instance: neoforge-grafana-storage
    app.kubernetes.io/component: storage
    app.kubernetes.io/part-of: neoforge
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: neoforge-standard
---
# AlertManager deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: neoforge-monitoring
  labels:
    app: alertmanager
    component: alerting
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: neoforge-alertmanager
    app.kubernetes.io/component: alerting
    app.kubernetes.io/part-of: neoforge
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: alertmanager
      component: alerting
  template:
    metadata:
      labels:
        app: alertmanager
        component: alerting
    spec:
      securityContext:
        runAsUser: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        fsGroup: 65534
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        imagePullPolicy: IfNotPresent
        args:
        - --config.file=/etc/alertmanager/alertmanager.yml
        - --storage.path=/alertmanager
        - --web.external-url=https://monitoring.neoforge.example.com/alertmanager
        - --cluster.advertise-address=0.0.0.0:9093
        ports:
        - containerPort: 9093
          name: web
        volumeMounts:
        - name: alertmanager-config
          mountPath: /etc/alertmanager
        - name: alertmanager-storage
          mountPath: /alertmanager
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9093
          initialDelaySeconds: 30
          periodSeconds: 15
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9093
          initialDelaySeconds: 5
          periodSeconds: 5
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      volumes:
      - name: alertmanager-config
        configMap:
          name: alertmanager-config
      - name: alertmanager-storage
        persistentVolumeClaim:
          claimName: alertmanager-storage
---
# AlertManager service
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: neoforge-monitoring
  labels:
    app: alertmanager
    component: alerting
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: neoforge-alertmanager
    app.kubernetes.io/component: alerting
    app.kubernetes.io/part-of: neoforge
spec:
  type: ClusterIP
  ports:
  - port: 9093
    targetPort: 9093
    name: web
  selector:
    app: alertmanager
    component: alerting
---
# AlertManager storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-storage
  namespace: neoforge-monitoring
  labels:
    app: alertmanager
    component: storage
    app.kubernetes.io/name: alertmanager-storage
    app.kubernetes.io/instance: neoforge-alertmanager-storage
    app.kubernetes.io/component: storage
    app.kubernetes.io/part-of: neoforge
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
  storageClassName: neoforge-standard